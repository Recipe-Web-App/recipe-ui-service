name: âš¡ Performance Monitoring

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
    # Run comprehensive performance analysis weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      test-type:
        description: 'Performance test type'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - lighthouse
          - vitals
          - load
          - bundle
          - memory

env:
  BUN_VERSION: 'latest'
  LIGHTHOUSE_CI_TOKEN: ${{ secrets.LIGHTHOUSE_CI_TOKEN }}

concurrency:
  group: performance-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Job 1: Lighthouse Performance Audits
  lighthouse-audit:
    name: ğŸ® Lighthouse Audit
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event.inputs.test-type == 'all' || github.event.inputs.test-type == 'lighthouse' || github.event.inputs.test-type == ''

    strategy:
      matrix:
        url-path: ['/', '/recipes', '/recipes/new', '/profile']
        device: ['desktop', 'mobile']

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¦ Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: ğŸ”§ Install dependencies
        run: bun install --frozen-lockfile

      - name: ğŸ—ï¸ Build application
        run: bun run build

      - name: ğŸš€ Start application
        run: |
          bun run start &
          bunx wait-on http://localhost:3000 --timeout 60000
        env:
          CI: true

      - name: ğŸ® Run Lighthouse CI
        run: |
          bunx lighthouse-ci autorun \
            --config=lighthouserc.js \
            --collect.url="http://localhost:3000${{ matrix.url-path }}" \
            --collect.settings.preset="${{ matrix.device }}" \
            --collect.numberOfRuns=3 \
            --assert.preset="lighthouse:recommended" \
            --assert.assertions.speed-index="error" \
            --assert.assertions.largest-contentful-paint="error" \
            --assert.assertions.cumulative-layout-shift="error" \
            --upload.target=temporary-public-storage

      - name: ğŸ“Š Parse Lighthouse results
        run: |
          # Extract key metrics from lighthouse results
          RESULTS_FILE=".lighthouseci/lhci_reports/manifest.json"
          if [ -f "$RESULTS_FILE" ]; then
            echo "ğŸ“Š Lighthouse Results for ${{ matrix.url-path }} (${{ matrix.device }}):"
            node -e "
              const manifest = JSON.parse(require('fs').readFileSync('$RESULTS_FILE', 'utf8'));
              const report = manifest[0];
              if (report) {
                console.log('Performance Score:', report.summary.performance);
                console.log('LCP:', report.summary.largestContentfulPaint + 'ms');
                console.log('CLS:', report.summary.cumulativeLayoutShift);
                console.log('FCP:', report.summary.firstContentfulPaint + 'ms');
                console.log('Speed Index:', report.summary.speedIndex + 'ms');
              }
            "
          fi

      - name: ğŸ“¤ Upload Lighthouse artifacts
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: lighthouse-results-${{ matrix.device }}-${{ matrix.url-path }}-${{ github.run_id }}
          path: |
            .lighthouseci/
            lighthouse-report.html
          retention-days: 30

  # Job 2: Core Web Vitals Testing
  core-web-vitals:
    name: ğŸ¯ Core Web Vitals
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.test-type == 'all' || github.event.inputs.test-type == 'vitals' || github.event.inputs.test-type == ''

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¦ Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: ğŸ”§ Install dependencies
        run: bun install --frozen-lockfile

      - name: ğŸ­ Install Playwright
        run: bunx playwright install --with-deps chromium

      - name: ğŸ—ï¸ Build application
        run: bun run build

      - name: ğŸš€ Start application
        run: |
          bun run start &
          bunx wait-on http://localhost:3000 --timeout 60000
        env:
          CI: true

      - name: ğŸ¯ Measure Core Web Vitals
        run: bun run perf:vitals

      - name: ğŸ“Š Validate Web Vitals thresholds
        run: |
          echo "ğŸ¯ Validating Core Web Vitals against thresholds..."
          node -e "
            const results = JSON.parse(require('fs').readFileSync('performance-results/web-vitals.json', 'utf8'));
            const thresholds = {
              LCP: 2500, // Good: <= 2.5s
              CLS: 0.1,  // Good: <= 0.1
              FID: 100,  // Good: <= 100ms
              FCP: 1800, // Good: <= 1.8s
              TTFB: 600  // Good: <= 600ms
            };

            let failures = 0;
            Object.entries(results).forEach(([metric, value]) => {
              const threshold = thresholds[metric];
              const status = value <= threshold ? 'âœ… PASS' : 'âŒ FAIL';
              console.log(\`\${metric}: \${value} (threshold: \${threshold}) \${status}\`);
              if (value > threshold) failures++;
            });

            if (failures > 0) {
              console.log(\`\\nâŒ \${failures} Core Web Vitals metrics failed thresholds\`);
              process.exit(1);
            } else {
              console.log('\\nğŸ‰ All Core Web Vitals metrics passed!');
            }
          "

      - name: ğŸ“¤ Upload Web Vitals results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: web-vitals-results
          path: |
            performance-results/
            test-results/
          retention-days: 30

  # Job 3: Load Testing
  load-testing:
    name: ğŸ”¥ Load Testing
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: github.event.inputs.test-type == 'all' || github.event.inputs.test-type == 'load' || github.event.inputs.test-type == ''

    strategy:
      matrix:
        scenario:
          - name: 'normal-load'
            users: 50
            duration: 300
          - name: 'peak-load'
            users: 200
            duration: 180
          - name: 'stress-test'
            users: 500
            duration: 120

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¦ Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: ğŸ”§ Install dependencies
        run: bun install --frozen-lockfile

      - name: ğŸ—ï¸ Build application
        run: bun run build

      - name: ğŸš€ Start application
        run: |
          bun run start &
          bunx wait-on http://localhost:3000 --timeout 60000
        env:
          CI: true
          NODE_ENV: production

      - name: ğŸ”¥ Run load test - ${{ matrix.scenario.name }}
        run: |
          echo "ğŸ”¥ Running load test: ${{ matrix.scenario.name }}"
          echo "Users: ${{ matrix.scenario.users }}, Duration: ${{ matrix.scenario.duration }}s"

          bunx autocannon \
            --connections ${{ matrix.scenario.users }} \
            --duration ${{ matrix.scenario.duration }} \
            --json \
            --output load-test-${{ matrix.scenario.name }}.json \
            http://localhost:3000

      - name: ğŸ“Š Analyze load test results
        run: |
          echo "ğŸ“Š Load Test Results - ${{ matrix.scenario.name }}:"
          node -e "
            const results = JSON.parse(require('fs').readFileSync('load-test-${{ matrix.scenario.name }}.json', 'utf8'));
            console.log('Requests/sec:', results.requests.average);
            console.log('Latency avg:', results.latency.average + 'ms');
            console.log('Latency p95:', results.latency.p95 + 'ms');
            console.log('Latency p99:', results.latency.p99 + 'ms');
            console.log('Throughput:', results.throughput.average + ' bytes/sec');
            console.log('Total requests:', results.requests.total);
            console.log('Error rate:', ((results.errors / results.requests.total) * 100).toFixed(2) + '%');

            // Performance thresholds
            const thresholds = {
              'normal-load': { maxLatencyP95: 500, minRps: 100 },
              'peak-load': { maxLatencyP95: 1000, minRps: 50 },
              'stress-test': { maxLatencyP95: 2000, minRps: 20 }
            };

            const threshold = thresholds['${{ matrix.scenario.name }}'];
            const p95Latency = results.latency.p95;
            const rps = results.requests.average;

            console.log('\\nğŸ¯ Performance Validation:');
            console.log('P95 Latency:', p95Latency <= threshold.maxLatencyP95 ? 'âœ… PASS' : 'âŒ FAIL', '(' + p95Latency + 'ms <= ' + threshold.maxLatencyP95 + 'ms)');
            console.log('Requests/sec:', rps >= threshold.minRps ? 'âœ… PASS' : 'âŒ FAIL', '(' + rps + ' >= ' + threshold.minRps + ')');
          "

      - name: ğŸ“¤ Upload load test results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: load-test-results-${{ matrix.scenario.name }}
          path: |
            load-test-*.json
            performance-results/
          retention-days: 7

  # Job 4: Bundle Size Analysis
  bundle-analysis:
    name: ğŸ“¦ Bundle Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.test-type == 'all' || github.event.inputs.test-type == 'bundle' || github.event.inputs.test-type == ''

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¦ Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: ğŸ”§ Install dependencies
        run: bun install --frozen-lockfile

      - name: ğŸ—ï¸ Build with bundle analysis
        run: |
          ANALYZE=true bun run build
          bun run size-limit
        env:
          CI: true

      - name: ğŸ“Š Generate bundle report
        run: |
          echo "ğŸ“¦ Bundle Size Analysis:" > bundle-report.md
          echo "" >> bundle-report.md

          # Size-limit report
          echo "## Size Limits" >> bundle-report.md
          bun run size-limit --json > size-limit-results.json || true

          if [ -f "size-limit-results.json" ]; then
            node -e "
              const results = JSON.parse(require('fs').readFileSync('size-limit-results.json', 'utf8'));
              results.forEach(result => {
                console.log('| ' + result.name + ' | ' + result.size + ' | ' + result.limit + ' | ' + (result.size <= result.limit ? 'âœ…' : 'âŒ') + ' |');
              });
            " >> bundle-report.md
          fi

          echo "" >> bundle-report.md
          echo "## Bundle Analysis" >> bundle-report.md

          # Next.js bundle analysis
          if [ -f ".next/analyze/bundle-analyzer-client.html" ]; then
            echo "- ğŸ“Š Client bundle analysis available in artifacts" >> bundle-report.md
          fi

          if [ -f ".next/analyze/bundle-analyzer-server.html" ]; then
            echo "- ğŸ–¥ï¸ Server bundle analysis available in artifacts" >> bundle-report.md
          fi

          echo "" >> bundle-report.md
          echo "Generated on: $(date)" >> bundle-report.md

      - name: ğŸ“¤ Upload bundle analysis
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: bundle-analysis
          path: |
            .next/analyze/
            bundle-report.md
            size-limit-results.json
          retention-days: 30

      - name: ğŸ’¬ Comment bundle size on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');

            if (fs.existsSync('bundle-report.md')) {
              const report = fs.readFileSync('bundle-report.md', 'utf8');

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: 'ğŸ“¦ **Bundle Size Report**\n\n' + report
              });
            }

  # Job 5: Memory Profiling
  memory-profiling:
    name: ğŸ§  Memory Profiling
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event.inputs.test-type == 'all' || github.event.inputs.test-type == 'memory' || github.event_name == 'schedule'

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¦ Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: ğŸ”§ Install dependencies
        run: bun install --frozen-lockfile

      - name: ğŸ—ï¸ Build application
        run: bun run build

      - name: ğŸ§  Memory profiling with Clinic.js
        run: |
          # Start application with memory profiling
          timeout 300 bunx clinic doctor --open=false --on-port='echo "Application started for profiling"' -- bun run start || true

          echo "ğŸ§  Memory profiling completed"

      - name: ğŸ“Š Analyze memory usage
        run: |
          # Generate memory report
          echo "# ğŸ§  Memory Profile Report" > memory-report.md
          echo "" >> memory-report.md
          echo "Generated on: $(date)" >> memory-report.md
          echo "" >> memory-report.md

          # Check if clinic files exist
          if ls .clinic/* 1> /dev/null 2>&1; then
            echo "ğŸ“Š Memory profiling data available in artifacts" >> memory-report.md
            echo "" >> memory-report.md
            echo "## Analysis Files:" >> memory-report.md
            echo "- Memory usage patterns" >> memory-report.md
            echo "- GC activity logs" >> memory-report.md
            echo "- Performance recommendations" >> memory-report.md
          else
            echo "âš ï¸ No memory profiling data generated" >> memory-report.md
          fi

      - name: ğŸ¯ Memory leak detection
        run: |
          # Basic memory leak detection
          echo "ğŸ” Running memory leak detection..."
          bun run test:unit --detectLeaks --forceExit
          echo "âœ… Memory leak detection completed"

      - name: ğŸ“¤ Upload memory profiling results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: memory-profiling-results
          path: |
            .clinic/
            memory-report.md
            *.clinic-doctor*
          retention-days: 7

  # Job 6: Performance Regression Detection
  regression-detection:
    name: ğŸ“ˆ Regression Detection
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [lighthouse-audit, core-web-vitals, bundle-analysis]
    if: always() && github.event_name == 'pull_request'

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v6

      - name: ğŸ“¥ Download performance results
        uses: actions/download-artifact@v7
        with:
          path: performance-results
          pattern: '*-results*'
          merge-multiple: true

      - name: ğŸ“Š Compare with baseline
        env:
          PR_NUMBER: ${{ github.event.number }}
          HEAD_REF: ${{ github.head_ref }}
          BASE_REF: ${{ github.base_ref }}
        run: |
          echo "ğŸ“ˆ Performance Regression Analysis" > regression-report.md
          echo "" >> regression-report.md
          echo "**PR:** #$PR_NUMBER" >> regression-report.md
          echo "**Branch:** $HEAD_REF" >> regression-report.md
          echo "**Base:** $BASE_REF" >> regression-report.md
          echo "" >> regression-report.md

          # Placeholder for actual regression detection logic
          echo "## ğŸ¯ Core Web Vitals" >> regression-report.md
          echo "| Metric | Current | Baseline | Change | Status |" >> regression-report.md
          echo "|--------|---------|----------|---------|--------|" >> regression-report.md
          echo "| LCP    | TBD     | TBD      | TBD     | â³     |" >> regression-report.md
          echo "| CLS    | TBD     | TBD      | TBD     | â³     |" >> regression-report.md
          echo "| FCP    | TBD     | TBD      | TBD     | â³     |" >> regression-report.md
          echo "" >> regression-report.md

          echo "## ğŸ“¦ Bundle Size" >> regression-report.md
          echo "| Bundle | Current | Baseline | Change | Status |" >> regression-report.md
          echo "|--------|---------|----------|---------|--------|" >> regression-report.md
          echo "| Total  | TBD     | TBD      | TBD     | â³     |" >> regression-report.md
          echo "" >> regression-report.md

          echo "## ğŸ® Lighthouse Scores" >> regression-report.md
          echo "| Page | Performance | Baseline | Change | Status |" >> regression-report.md
          echo "|------|-------------|----------|---------|--------|" >> regression-report.md
          echo "| /    | TBD         | TBD      | TBD     | â³     |" >> regression-report.md
          echo "" >> regression-report.md

          echo "*Note: Actual regression detection requires baseline data from the main branch.*" >> regression-report.md

      - name: ğŸ’¬ Comment regression analysis on PR
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('regression-report.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  # Consolidation Job
  performance-summary:
    name: ğŸ“‹ Performance Summary
    runs-on: ubuntu-latest
    if: always()
    needs:
      - lighthouse-audit
      - core-web-vitals
      - load-testing
      - bundle-analysis
      - memory-profiling

    steps:
      - name: ğŸ“Š Generate performance summary
        run: |
          echo "# âš¡ Performance Test Summary" > performance-summary.md
          echo "" >> performance-summary.md
          echo "**Date:** $(date)" >> performance-summary.md
          echo "**Commit:** ${{ github.sha }}" >> performance-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> performance-summary.md
          echo "" >> performance-summary.md
          echo "## Test Results" >> performance-summary.md
          echo "- ğŸ® Lighthouse Audit: ${{ needs.lighthouse-audit.result }}" >> performance-summary.md
          echo "- ğŸ¯ Core Web Vitals: ${{ needs.core-web-vitals.result }}" >> performance-summary.md
          echo "- ğŸ”¥ Load Testing: ${{ needs.load-testing.result }}" >> performance-summary.md
          echo "- ğŸ“¦ Bundle Analysis: ${{ needs.bundle-analysis.result }}" >> performance-summary.md
          echo "- ğŸ§  Memory Profiling: ${{ needs.memory-profiling.result }}" >> performance-summary.md
          echo "" >> performance-summary.md

          # Overall status
          if [[ "${{ needs.lighthouse-audit.result }}" == "success" &&
                "${{ needs.core-web-vitals.result }}" == "success" &&
                "${{ needs.load-testing.result }}" == "success" &&
                "${{ needs.bundle-analysis.result }}" == "success" ]]; then
            echo "âœ… **Overall Status: PASSED** - All performance tests succeeded" >> performance-summary.md
          else
            echo "âŒ **Overall Status: FAILED** - Some performance tests failed" >> performance-summary.md
          fi

      - name: ğŸ“¤ Upload performance summary
        uses: actions/upload-artifact@v6
        with:
          name: performance-summary
          path: performance-summary.md
          retention-days: 90

      - name: ğŸ“¬ Performance notification
        if: github.ref == 'refs/heads/main'
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            âš¡ **Performance Test Results** for ${{ github.repository }}

            - ğŸ® Lighthouse: ${{ needs.lighthouse-audit.result }}
            - ğŸ¯ Web Vitals: ${{ needs.core-web-vitals.result }}
            - ğŸ”¥ Load Testing: ${{ needs.load-testing.result }}
            - ğŸ“¦ Bundle Size: ${{ needs.bundle-analysis.result }}
            - ğŸ§  Memory: ${{ needs.memory-profiling.result }}

            Branch: ${{ github.ref_name }}
            Commit: ${{ github.sha }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
